# Architecture Technique & Cognitive - Overhearing Agents

Ce document pr√©sente l'architecture globale du projet. Il d√©taille √† la fois la "m√©canique" technique (traitement du signal, mod√®les) et le "cerveau" du PNJ (m√©moire, personnalit√©, contexte).


## üõ†Ô∏è Partie 1 : Stack Technologique (Le Moteur)

Cette section justifie les outils utilis√©s pour assurer la performance et le temps r√©el.

### 1. VAD (Voice Activity Detection)
*   **Outil :** `Silero-VAD`.
*   **R√¥le :** Le "Portier".
*   **Pourquoi ?** : Le micro √©coute en permanence. Sans VAD, le syst√®me enverrait du silence ou du bruit de fond au processeur. Cela gaspille des ressources (GPU) et fait "halluciner" le mod√®le (il invente des mots dans le bruit). Le VAD coupe le flux quand personne ne parle.

### 2. STT (Speech-to-Text)
*   **Outil :** `faster-whisper` (Impl√©mentation optimis√©e du mod√®le OpenAI).
*   **R√¥le :** L'"Oreille".
*   **Optimisation :** Utilisation de **Hot-Words** (injection de vocabulaire m√©tier) pour reconna√Ætre les noms propres fantaisie (ex: "Phandalin", "Tiamat") que le mod√®le standard √©corcherait.
*   **Pourquoi ?** : C'est le meilleur compromis pr√©cision/vitesse actuel pour transformer la parole naturelle en texte exploitable par le LLM.

### 3. Local LLM (Le Mod√®le)
*   **Outil :** `Ollama` tournant `Qwen2.5:3b` ou `Mistral`.
*   **R√¥le :** Le moteur d'intelligence brute.
*   **Pourquoi ?** :
    *   **Confidentialit√© :** Tout reste en local.
    *   **Latence :** Pas d'appel API r√©seau.
    *   **Taille :** Les mod√®les 3B-7B tournent fluidement sur des laptops gaming (RTX) avec une latence acceptable pour la conversation.

### 4. TTS (Text-to-Speech)
*   **Outil :** `Piper TTS` (Mod√®le `en_US-joe-medium`).
*   **R√¥le :** La "Bouche".
*   **Pourquoi ?** : Contrairement aux solutions "lourdes" (Tortoise) ou cloud (ElevenLabs), Piper g√©n√®re de l'audio en quelques millisecondes (< 200ms). C'est crucial pour √©viter le "blanc" g√™nant entre la r√©ponse du joueur et celle du NPC.

---

## üß† Partie 2 : Architecture Cognitive (Le Pilote)

Cette section explique comment **LangChain** orchestre le LLM pour cr√©er un personnage cr√©dible et coh√©rent.

### 1. Orchestration & Router
*   **Outil :** `LangChain Router Chain`.
*   **Concept :** L'agent ne r√©pond pas √† tout. Le Router analyse l'intention de la phrase transcrite :
    *   *Si "Je demande au tavernier..."* -> **Activation**.
    *   *Si "Passe-moi les chips..."* -> **Ignorer**.

### 2. Gestion de la M√©moire (Memory)
Un LLM brut est amn√©sique. Nous utilisons deux types de m√©moires :

*   **A. M√©moire Court Terme (Short-Term):**
    *   *Composant :* `ConversationSummaryBufferMemory`.
    *   *Fonctionnement :* Garde les derniers √©changes (ex: 5) en texte brut pour la fluidit√©, et **r√©sume** automatiquement les √©changes plus anciens pour √©conomiser la fen√™tre de contexte.
    *   *Usage :* Se souvenir du nom du joueur ou de sa commande r√©cente.

*   **B. M√©moire Long Terme (RAG / Lore):**
    *   *Composant :* `ChromaDB` (Vector Store) + `Retriever`.
    *   *Fonctionnement :* Base de donn√©es contenant l'histoire du monde ("Lore"). Quand le joueur pose une question sur l'univers, le syst√®me retrouve le passage pertinent et l'injecte dans le prompt.
    *   *Usage :* Conna√Ætre l'histoire du Roi ou la g√©ographie sans l'avoir apprise par c≈ìur.

### 3. Contexte Dynamique & Persona
Pour que le NPC soit vivant, son "System Prompt" est reconstruit dynamiquement √† chaque tour de parole :

```text
Prompt = [Persona Statique] + [√âtat de la Sc√®ne] + [M√©moire] + [Lore RAG]
```

*   **Persona :** "Tu es Joe, un nain grincheux."
*   **√âtat de la Sc√®ne (Inject√©) :** "Il fait nuit, la taverne est vide, les joueurs sont arm√©s."
*   **R√®gle d'or (Guardrails) :** Interdiction d'utiliser des emojis ou des actions entre ast√©risques (`*sourit*`), car le TTS les lirait √† haute voix, brisant l'immersion.

---

## üìú Exemple Concret : "L'Affaire du Dragon"

Voici la trace d'ex√©cution interne du syst√®me lorsqu'un joueur pose une question complexe.

**Sc√©nario :** Les joueurs sont dans la taverne de Joe. Le joueur "L√©o" pose une question sur une rumeur locale.

**1. Input Joueur (Audio)**
> "H√© Joe, t'as entendu parler du Dragon Blanc dans les montagnes ?"

**2. Traitement STT (Processing)**
*   `VAD` : D√©tecte une voix (ignore le bruit des verres).
*   `Whisper` : Transcrit "Hey Joe, have you heard about the White Dragon in the mountains?".
*   `Router` : D√©tecte le mot-cl√© "Joe" + Intention de question -> **ACTIVATION**.

**3. R√©cup√©ration de Connaissance (RAG)**
*   Le syst√®me cherche "White Dragon" et "Mountains" dans `ChromaDB`.
*   *R√©sultat trouv√© (Lore.txt) :* "Une rumeur dit que Cryovain, un dragon blanc cruel, a √©t√© vu au sommet du Pic Icespire."

**4. Assemblage du Prompt (LangChain)**
Le LLM re√ßoit ceci (simplifi√©) :
> **System:** Tu es Joe, un tavernier nain peureux. Tu parles d'une voix grave.
> **Contexte:** Il fait nuit. Ambiance calme.
> **Lore:** Le dragon s'appelle Cryovain, il vit au Pic Icespire.
> **M√©moire:** L√©o t'a salu√© il y a 2 minutes.
> **User:** T'as entendu parler du Dragon Blanc ?

**5. G√©n√©ration (LLM Output)**
> "Par ma barbe... Tu parles de Cryovain ? Ce monstre g√®le le sang des voyageurs ! Ne t'approche pas du Pic Icespire si tu tiens √† la vie, petit !"

**6. Sortie Audio (TTS)**
*   `Piper` g√©n√®re l'audio avec le mod√®le vocal "Joe".
*   Les haut-parleurs jouent la r√©ponse.